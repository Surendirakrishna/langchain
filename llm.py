# -*- coding: utf-8 -*-
"""Llm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GtBSGLx65vjccTpAuQ-39fhRNJBRn3A7
"""

#!pip install streamlit # Install Streamlit package
#!pip install langchain-community

from langchain_core.prompts import ChatPromptTemplate # Corrected the typo from ChatPromtTemplate to ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.llms import ollama
import streamlit as st # Now this line should work without errors

st.title("Divine")
input_txt = st.text_input("How Can i help you today ?") # Changed st.title_input to st.text_input

prompt = ChatPromptTemplate.from_messages(
    [("system","You are a helpful Ai assistant. Your name is Divine"),
     ("user", "user query :{query}")
    ])

llm = ollama.Ollama(model="llama2")

output_parsers = StrOutputParser()

chain = prompt | llm | output_parsers

if input_txt:
    st.write(chain.invoke({"query":input_txt}))